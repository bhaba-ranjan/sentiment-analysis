{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173cbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e49396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a9fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3880692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\",names=[\"sentiments\", \"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c00c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(data_frame):\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.lower())\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.translate(str.maketrans('', '', string.punctuation)))\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.translate(str.maketrans('', '', string.digits)))\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: re.sub(\"r[^a-z]\",'',review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e046e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cleaning(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68be92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def tokenize_data(data_frame):\n",
    "    data_frame['words'] = data_frame.reviews.apply(lambda review: nltk.word_tokenize(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc46b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666a90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(list):\n",
    "    stop_words_removed = []\n",
    "    for i in list:\n",
    "        if i not in stopwords:\n",
    "            stop_words_removed.append(i)\n",
    "    return stop_words_removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5074d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['stop_words_cleaned'] = train_data.words.apply(lambda word_list: remove_stopwords(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc2ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all')\n",
    "def tag_pos(list_of_words):\n",
    "    return nltk.pos_tag(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0dd626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of lemma words after taggin with pos\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "def find_lemma_word(word):\n",
    "    lemma_words=[]\n",
    "    words_with_pos = tag_pos(word)\n",
    "    for word in words_with_pos:\n",
    "        if word[1].startswith('NN'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='n'))\n",
    "        elif word[1].startswith('VB'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='v'))\n",
    "        elif word[1].startswith('JJ'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='a'))\n",
    "        elif word[1].startswith('RB'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='r'))\n",
    "        else:\n",
    "            lemma_words.append(word[0])\n",
    "            \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8a3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lemma_word'] = train_data.stop_words_cleaned.apply(lambda word_list: find_lemma_word(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f99f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cleaned_review'] = train_data.lemma_word.apply(lambda review_list: \" \".join(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c917831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb633a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_review, test_review, train_sentiment, test_sentiment =train_test_split(train_data.cleaned_review,train_data.sentiments,shuffle=True,random_state=0,stratify=train_data.sentiments,train_size=.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76a12ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vectorizer = TfidfVectorizer(use_idf=False,norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1eac9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_features = count_vectorizer.fit_transform(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a837b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "inital_feat_array = initial_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd7912f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_top_features = TfidfVectorizer(max_features=int(len(count_vectorizer.vocabulary_)*.20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23616914",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_matrix = count_vectorizer_top_features.fit_transform(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a95ea829",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_array = selected_feature_matrix.toarray()\n",
    "selected_test = count_vectorizer_top_features.transform(test_review)\n",
    "selected_test_features = selected_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9121bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(selected_feature_array,columns=count_vectorizer_top_features.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abd821da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiments'] = np.array(train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e937f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in df.columns.values:\n",
    "    arr.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6b0d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17909"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(arr))\n",
    "arr.remove('sentiments')\n",
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64c848c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aabc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>zoolights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>zorbas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>zucchini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>zumba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_variable\n",
       "0                   aa\n",
       "1                  aaa\n",
       "2                 aabc\n",
       "3                aaron\n",
       "4                   ab\n",
       "...                ...\n",
       "17904              zoo\n",
       "17905        zoolights\n",
       "17906           zorbas\n",
       "17907         zucchini\n",
       "17908            zumba\n",
       "\n",
       "[17909 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep_chi_table = pd.DataFrame(arr, columns=['feature_variable'])\n",
    "df_prep_chi_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e3f15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_chi_table['-1'] = df_prep_chi_table.feature_variable.apply(lambda feat: df.loc[df['sentiments']== -1, feat].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5f4b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_chi_table['+1'] = df_prep_chi_table.feature_variable.apply(lambda feat: df.loc[df['sentiments']== 1, feat].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67f8fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = df_prep_chi_table['+1'].sum()+df_prep_chi_table['-1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "227ac6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_chi_table['sum_total'] = df_prep_chi_table['+1']+df_prep_chi_table['-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5fef82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_variable</th>\n",
       "      <th>-1</th>\n",
       "      <th>+1</th>\n",
       "      <th>sum_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>0.250140</td>\n",
       "      <td>0.352377</td>\n",
       "      <td>0.602517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa</td>\n",
       "      <td>1.251897</td>\n",
       "      <td>1.803329</td>\n",
       "      <td>3.055226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aabc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694114</td>\n",
       "      <td>0.694114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron</td>\n",
       "      <td>0.560806</td>\n",
       "      <td>0.794011</td>\n",
       "      <td>1.354816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab</td>\n",
       "      <td>0.459362</td>\n",
       "      <td>0.266657</td>\n",
       "      <td>0.726019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>zoo</td>\n",
       "      <td>8.432407</td>\n",
       "      <td>19.327627</td>\n",
       "      <td>27.760033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>zoolights</td>\n",
       "      <td>0.090006</td>\n",
       "      <td>1.033548</td>\n",
       "      <td>1.123554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>zorbas</td>\n",
       "      <td>1.474177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.474177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>3.965220</td>\n",
       "      <td>2.905112</td>\n",
       "      <td>6.870332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>zumba</td>\n",
       "      <td>0.254515</td>\n",
       "      <td>0.745126</td>\n",
       "      <td>0.999641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_variable        -1         +1  sum_total\n",
       "0                   aa  0.250140   0.352377   0.602517\n",
       "1                  aaa  1.251897   1.803329   3.055226\n",
       "2                 aabc  0.000000   0.694114   0.694114\n",
       "3                aaron  0.560806   0.794011   1.354816\n",
       "4                   ab  0.459362   0.266657   0.726019\n",
       "...                ...       ...        ...        ...\n",
       "17904              zoo  8.432407  19.327627  27.760033\n",
       "17905        zoolights  0.090006   1.033548   1.123554\n",
       "17906           zorbas  1.474177   0.000000   1.474177\n",
       "17907         zucchini  3.965220   2.905112   6.870332\n",
       "17908            zumba  0.254515   0.745126   0.999641\n",
       "\n",
       "[17909 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep_chi_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d97de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd0d2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765788e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ece56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77004b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb86e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16774d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987bd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced4378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1259585",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_neg_sentiment = np.array(df_prep_chi_table['-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e626056",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_pos_sentiment = np.array(df_prep_chi_table['+1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c86f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_row_sum = np.array(df_prep_chi_table['sum_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb2ebb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_val(x ,y ,row_total, x_total, y_total, sum_total):\n",
    "    exp_x=[]\n",
    "    exp_y=[]\n",
    "    for i in range(0,len(x)):\n",
    "        exp_x.append(row_total[i]*x_total/sum_total)\n",
    "        exp_y.append(row_total[i]*y_total/sum_total)\n",
    "    return exp_x,exp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "db802fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_col_sum = df_prep_chi_table['-1'].sum()\n",
    "pos_col_sum = df_prep_chi_table['+1'].sum()\n",
    "e_neg,e_pos = calculate_expected_val(array_neg_sentiment, array_pos_sentiment, array_row_sum,neg_col_sum ,pos_col_sum, total_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21829577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2f83fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp['+1'] = e_pos\n",
    "df_exp['-1'] = e_neg\n",
    "df_chi_value = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c4c1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi_value['-1'] = ((df_prep_chi_table['-1']- df_exp['-1'])**2)/df_exp['-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6f9fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi_value['+1'] = ((df_prep_chi_table['+1']- df_exp['+1'])**2)/df_exp['+1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa138f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014866</td>\n",
       "      <td>0.016728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082679</td>\n",
       "      <td>0.093029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367502</td>\n",
       "      <td>0.413511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.038423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.016452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>2.670737</td>\n",
       "      <td>3.005096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>0.428477</td>\n",
       "      <td>0.482120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>0.616487</td>\n",
       "      <td>0.693667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>0.029520</td>\n",
       "      <td>0.033216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>0.142626</td>\n",
       "      <td>0.160482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             -1        +1\n",
       "0      0.014866  0.016728\n",
       "1      0.082679  0.093029\n",
       "2      0.367502  0.413511\n",
       "3      0.034148  0.038423\n",
       "4      0.014621  0.016452\n",
       "...         ...       ...\n",
       "17904  2.670737  3.005096\n",
       "17905  0.428477  0.482120\n",
       "17906  0.616487  0.693667\n",
       "17907  0.029520  0.033216\n",
       "17908  0.142626  0.160482\n",
       "\n",
       "[17909 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chi_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3513e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chi_val = []\n",
    "for row in df_chi_value.itertuples():\n",
    "    max_chi_val.append(max(row[1],row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "689cd637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>+1</th>\n",
       "      <th>max_chi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014866</td>\n",
       "      <td>0.016728</td>\n",
       "      <td>0.016728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082679</td>\n",
       "      <td>0.093029</td>\n",
       "      <td>0.093029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367502</td>\n",
       "      <td>0.413511</td>\n",
       "      <td>0.413511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.038423</td>\n",
       "      <td>0.038423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>0.016452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>2.670737</td>\n",
       "      <td>3.005096</td>\n",
       "      <td>3.005096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>0.428477</td>\n",
       "      <td>0.482120</td>\n",
       "      <td>0.482120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>0.616487</td>\n",
       "      <td>0.693667</td>\n",
       "      <td>0.693667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>0.029520</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.033216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>0.142626</td>\n",
       "      <td>0.160482</td>\n",
       "      <td>0.160482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             -1        +1   max_chi\n",
       "0      0.014866  0.016728  0.016728\n",
       "1      0.082679  0.093029  0.093029\n",
       "2      0.367502  0.413511  0.413511\n",
       "3      0.034148  0.038423  0.038423\n",
       "4      0.014621  0.016452  0.016452\n",
       "...         ...       ...       ...\n",
       "17904  2.670737  3.005096  3.005096\n",
       "17905  0.428477  0.482120  0.482120\n",
       "17906  0.616487  0.693667  0.693667\n",
       "17907  0.029520  0.033216  0.033216\n",
       "17908  0.142626  0.160482  0.160482\n",
       "\n",
       "[17909 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chi_value['max_chi'] = max_chi_val\n",
    "df_chi_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "069b677a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17280, 17909)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3666051a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ...,  1, -1,  1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = np.array(train_sentiment)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c0410e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = np.array(df_chi_value['+1'])\n",
    "neg_weight = np.array(df_chi_value['-1'])\n",
    "mx_weight = np.array(df_chi_value['max_chi'])\n",
    "\n",
    "def weighted_feature(selected_feature_array, sentiment):\n",
    "    weighted_feat_array = []\n",
    "    ts = np.array(sentiment)\n",
    "    for i in range(0, len(sentiment)):        \n",
    "        if ts[i] == 1:\n",
    "            weighted_feat_array.append(np.multiply(selected_feature_array[i],pos_weight))\n",
    "        else:\n",
    "            weighted_feat_array.append(np.multiply(selected_feature_array[i],neg_weight))\n",
    "    return weighted_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb8f00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_feature_train = weighted_feature(selected_feature_array, train_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cef1d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_feature_k(selected_feature_array, sentiment):\n",
    "    weighted_feat_array = []\n",
    "    ts = np.array(sentiment)\n",
    "    for i in range(0, len(sentiment)):        \n",
    "        if ts[i] == 1:\n",
    "            weighted_feat_array.append(np.multiply(selected_feature_array[i],mx_weight))\n",
    "        else:\n",
    "            weighted_feat_array.append(np.multiply(selected_feature_array[i],mx_weight))\n",
    "    return weighted_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb06647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_feature_test = weighted_feature_k(selected_test_features, test_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2df5e1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17909,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_feature_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bbd0e28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "track_precision=[]\n",
    "# for i in range(5,21):\n",
    "#     print(i)\n",
    "classifer = KNeighborsClassifier(n_neighbors=14,n_jobs=3,weights='distance')\n",
    "classifer.fit(weighted_feature_train, train_sentiment)\n",
    "sentiments_predict = classifer.predict(weighted_feature_test)\n",
    "score = metrics.accuracy_score(test_sentiment,sentiments_predict)\n",
    "print(score)\n",
    "track_precision.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e3a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35e12ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# outfile = open('results.csv','w')\n",
    "# out = csv.writer(outfile)\n",
    "# out.writerows(map(lambda x: [x], score_predict))\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d17ff5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_df = pd.read_csv('1661892619_9579706_test_file.csv', names=['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7a101b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cleaning(result_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a1d99f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_data(result_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c52334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_df['stop_words_cleaned'] = result_test_df.words.apply(lambda word_list: remove_stopwords(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "06877340",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_df['lemma_word'] = result_test_df.stop_words_cleaned.apply(lambda word_list: find_lemma_word(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6b3481d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_df['cleaned_review'] = result_test_df.lemma_word.apply(lambda review_list: \" \".join(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "805f2e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>words</th>\n",
       "      <th>stop_words_cleaned</th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>got takeout from here last night and it was ho...</td>\n",
       "      <td>[got, takeout, from, here, last, night, and, i...</td>\n",
       "      <td>[got, takeout, last, night, horrible, somethin...</td>\n",
       "      <td>[get, takeout, last, night, horrible, somethin...</td>\n",
       "      <td>get takeout last night horrible something must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>girls are sweet and prices are reasonable the ...</td>\n",
       "      <td>[girls, are, sweet, and, prices, are, reasonab...</td>\n",
       "      <td>[girls, sweet, prices, reasonable, stand, bed,...</td>\n",
       "      <td>[girl, sweet, price, reasonable, stand, bed, h...</td>\n",
       "      <td>girl sweet price reasonable stand bed hot make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rudest people i have eveencountered  husband a...</td>\n",
       "      <td>[rudest, people, i, have, eveencountered, husb...</td>\n",
       "      <td>[rudest, people, eveencountered, husband, wife...</td>\n",
       "      <td>[rudest, people, eveencountered, husband, wife...</td>\n",
       "      <td>rudest people eveencountered husband wife own ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this airport is only coveted fothe destination...</td>\n",
       "      <td>[this, airport, is, only, coveted, fothe, dest...</td>\n",
       "      <td>[airport, coveted, fothe, destination, leads, ...</td>\n",
       "      <td>[airport, covet, fothe, destination, lead, fli...</td>\n",
       "      <td>airport covet fothe destination lead flier vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the last  months have shown a steady decline i...</td>\n",
       "      <td>[the, last, months, have, shown, a, steady, de...</td>\n",
       "      <td>[last, months, shown, steady, decline, pisspoo...</td>\n",
       "      <td>[last, month, show, steady, decline, pisspoose...</td>\n",
       "      <td>last month show steady decline pisspooservice ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  got takeout from here last night and it was ho...   \n",
       "1  girls are sweet and prices are reasonable the ...   \n",
       "2  rudest people i have eveencountered  husband a...   \n",
       "3  this airport is only coveted fothe destination...   \n",
       "4  the last  months have shown a steady decline i...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [got, takeout, from, here, last, night, and, i...   \n",
       "1  [girls, are, sweet, and, prices, are, reasonab...   \n",
       "2  [rudest, people, i, have, eveencountered, husb...   \n",
       "3  [this, airport, is, only, coveted, fothe, dest...   \n",
       "4  [the, last, months, have, shown, a, steady, de...   \n",
       "\n",
       "                                  stop_words_cleaned  \\\n",
       "0  [got, takeout, last, night, horrible, somethin...   \n",
       "1  [girls, sweet, prices, reasonable, stand, bed,...   \n",
       "2  [rudest, people, eveencountered, husband, wife...   \n",
       "3  [airport, coveted, fothe, destination, leads, ...   \n",
       "4  [last, months, shown, steady, decline, pisspoo...   \n",
       "\n",
       "                                          lemma_word  \\\n",
       "0  [get, takeout, last, night, horrible, somethin...   \n",
       "1  [girl, sweet, price, reasonable, stand, bed, h...   \n",
       "2  [rudest, people, eveencountered, husband, wife...   \n",
       "3  [airport, covet, fothe, destination, lead, fli...   \n",
       "4  [last, month, show, steady, decline, pisspoose...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  get takeout last night horrible something must...  \n",
       "1  girl sweet price reasonable stand bed hot make...  \n",
       "2  rudest people eveencountered husband wife own ...  \n",
       "3  airport covet fothe destination lead flier vie...  \n",
       "4  last month show steady decline pisspooservice ...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test_feature = count_vectorizer_top_features.transform(result_test_df['cleaned_review'])\n",
    "result_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e69fdba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 17909)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_feature_array = result_test_feature.toarray()\n",
    "result_feature_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cc8d4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_feature_agg(selected_feature_array):\n",
    "    weighted_feat_array = []\n",
    "    for i in range(0, len(selected_feature_array)):        \n",
    "            weighted_feat_array.append(np.multiply(selected_feature_array[i],mx_weight))        \n",
    "    return weighted_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d02410bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_feature_weighted = weighted_feature_agg(result_feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "056e40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifer.predict(result_feature_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c5d4a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d61f442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "outfile = open('results.csv','w')\n",
    "out = csv.writer(outfile)\n",
    "out.writerows(map(lambda x: [x], prediction))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d1939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
