{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa791c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc8688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\",names=[\"sentiments\", \"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6cc661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(data_frame):\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.lower())\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.translate(str.maketrans('', '', string.punctuation)))\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.translate(str.maketrans('', '', string.digits)))\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: re.sub(\"r[^a-z]\",'',review))\n",
    "\n",
    "    \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def tokenize_data(data_frame):\n",
    "    data_frame['words'] = data_frame.reviews.apply(lambda review: nltk.word_tokenize(review))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(list):\n",
    "    stop_words_removed = []\n",
    "    for i in list:\n",
    "        if i not in stopwords:\n",
    "            stop_words_removed.append(i)\n",
    "    return stop_words_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e0dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cleaning(train_data)\n",
    "tokenize_data(train_data)\n",
    "train_data['stop_words_cleaned'] = train_data.words.apply(lambda word_list: remove_stopwords(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ac0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all')\n",
    "def tag_pos(list_of_words):\n",
    "    return nltk.pos_tag(list_of_words)\n",
    "\n",
    "#extraction of lemma words after taggin with pos\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "def find_lemma_word(word):\n",
    "    lemma_words=[]\n",
    "    words_with_pos = tag_pos(word)\n",
    "    for word in words_with_pos:\n",
    "        if word[1].startswith('NN'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='n'))\n",
    "        elif word[1].startswith('VB'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='v'))\n",
    "        elif word[1].startswith('JJ'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='a'))\n",
    "        elif word[1].startswith('RB'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='r'))\n",
    "        else:\n",
    "            lemma_words.append(word[0])\n",
    "            \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30451073",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lemma_word'] = train_data.stop_words_cleaned.apply(lambda word_list: find_lemma_word(word_list))\n",
    "train_data['cleaned_review'] = train_data.lemma_word.apply(lambda review_list: \" \".join(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b0dcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>reviews</th>\n",
       "      <th>words</th>\n",
       "      <th>stop_words_cleaned</th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>eat at fioris they said  youll like it they sa...</td>\n",
       "      <td>[eat, at, fioris, they, said, youll, like, it,...</td>\n",
       "      <td>[eat, fioris, said, youll, like, saidnnis, con...</td>\n",
       "      <td>[eat, fioris, say, youll, like, saidnnis, conv...</td>\n",
       "      <td>eat fioris say youll like saidnnis convenientl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>i just dont understand the appeal  ive tried t...</td>\n",
       "      <td>[i, just, dont, understand, the, appeal, ive, ...</td>\n",
       "      <td>[dont, understand, appeal, ive, tried, place, ...</td>\n",
       "      <td>[dont, understand, appeal, ive, tried, place, ...</td>\n",
       "      <td>dont understand appeal ive tried place twice t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this is my go to place foa really good beef en...</td>\n",
       "      <td>[this, is, my, go, to, place, foa, really, goo...</td>\n",
       "      <td>[go, place, foa, really, good, beef, enchilada...</td>\n",
       "      <td>[go, place, foa, really, good, beef, enchilada...</td>\n",
       "      <td>go place foa really good beef enchilada red sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>not impressed when i ordered the oyako bowl th...</td>\n",
       "      <td>[not, impressed, when, i, ordered, the, oyako,...</td>\n",
       "      <td>[impressed, ordered, oyako, bowl, conversation...</td>\n",
       "      <td>[impressed, order, oyako, bowl, conversation, ...</td>\n",
       "      <td>impressed order oyako bowl conversation go som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>this is the first time evei wrote a bad review...</td>\n",
       "      <td>[this, is, the, first, time, evei, wrote, a, b...</td>\n",
       "      <td>[first, time, evei, wrote, bad, review, frustr...</td>\n",
       "      <td>[first, time, evei, write, bad, review, frustr...</td>\n",
       "      <td>first time evei write bad review frustrate her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>-1</td>\n",
       "      <td>i was referred to go to this place by a buddy ...</td>\n",
       "      <td>[i, was, referred, to, go, to, this, place, by...</td>\n",
       "      <td>[referred, go, place, buddy, aftea, conversati...</td>\n",
       "      <td>[refer, go, place, buddy, aftea, conversation,...</td>\n",
       "      <td>refer go place buddy aftea conversation get sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>1</td>\n",
       "      <td>the food here was really good  we started off ...</td>\n",
       "      <td>[the, food, here, was, really, good, we, start...</td>\n",
       "      <td>[food, really, good, started, garlic, bread, c...</td>\n",
       "      <td>[food, really, good, start, garlic, bread, cov...</td>\n",
       "      <td>food really good start garlic bread cover toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>1</td>\n",
       "      <td>i eat at this place maybe  a week i am die har...</td>\n",
       "      <td>[i, eat, at, this, place, maybe, a, week, i, a...</td>\n",
       "      <td>[eat, place, maybe, week, die, hard, wing, fan...</td>\n",
       "      <td>[eat, place, maybe, week, die, hard, wing, fan...</td>\n",
       "      <td>eat place maybe week die hard wing fan best ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>1</td>\n",
       "      <td>phoenix airport is getting betteday by day  i ...</td>\n",
       "      <td>[phoenix, airport, is, getting, betteday, by, ...</td>\n",
       "      <td>[phoenix, airport, getting, betteday, day, pri...</td>\n",
       "      <td>[phoenix, airport, get, betteday, day, primari...</td>\n",
       "      <td>phoenix airport get betteday day primarily use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>-1</td>\n",
       "      <td>so when i was much youngei went to christos an...</td>\n",
       "      <td>[so, when, i, was, much, youngei, went, to, ch...</td>\n",
       "      <td>[much, youngei, went, christos, first, place, ...</td>\n",
       "      <td>[much, youngei, go, christos, first, place, es...</td>\n",
       "      <td>much youngei go christos first place escargot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiments                                            reviews  \\\n",
       "0              -1  eat at fioris they said  youll like it they sa...   \n",
       "1              -1  i just dont understand the appeal  ive tried t...   \n",
       "2               1  this is my go to place foa really good beef en...   \n",
       "3              -1  not impressed when i ordered the oyako bowl th...   \n",
       "4              -1  this is the first time evei wrote a bad review...   \n",
       "...           ...                                                ...   \n",
       "17995          -1  i was referred to go to this place by a buddy ...   \n",
       "17996           1  the food here was really good  we started off ...   \n",
       "17997           1  i eat at this place maybe  a week i am die har...   \n",
       "17998           1  phoenix airport is getting betteday by day  i ...   \n",
       "17999          -1  so when i was much youngei went to christos an...   \n",
       "\n",
       "                                                   words  \\\n",
       "0      [eat, at, fioris, they, said, youll, like, it,...   \n",
       "1      [i, just, dont, understand, the, appeal, ive, ...   \n",
       "2      [this, is, my, go, to, place, foa, really, goo...   \n",
       "3      [not, impressed, when, i, ordered, the, oyako,...   \n",
       "4      [this, is, the, first, time, evei, wrote, a, b...   \n",
       "...                                                  ...   \n",
       "17995  [i, was, referred, to, go, to, this, place, by...   \n",
       "17996  [the, food, here, was, really, good, we, start...   \n",
       "17997  [i, eat, at, this, place, maybe, a, week, i, a...   \n",
       "17998  [phoenix, airport, is, getting, betteday, by, ...   \n",
       "17999  [so, when, i, was, much, youngei, went, to, ch...   \n",
       "\n",
       "                                      stop_words_cleaned  \\\n",
       "0      [eat, fioris, said, youll, like, saidnnis, con...   \n",
       "1      [dont, understand, appeal, ive, tried, place, ...   \n",
       "2      [go, place, foa, really, good, beef, enchilada...   \n",
       "3      [impressed, ordered, oyako, bowl, conversation...   \n",
       "4      [first, time, evei, wrote, bad, review, frustr...   \n",
       "...                                                  ...   \n",
       "17995  [referred, go, place, buddy, aftea, conversati...   \n",
       "17996  [food, really, good, started, garlic, bread, c...   \n",
       "17997  [eat, place, maybe, week, die, hard, wing, fan...   \n",
       "17998  [phoenix, airport, getting, betteday, day, pri...   \n",
       "17999  [much, youngei, went, christos, first, place, ...   \n",
       "\n",
       "                                              lemma_word  \\\n",
       "0      [eat, fioris, say, youll, like, saidnnis, conv...   \n",
       "1      [dont, understand, appeal, ive, tried, place, ...   \n",
       "2      [go, place, foa, really, good, beef, enchilada...   \n",
       "3      [impressed, order, oyako, bowl, conversation, ...   \n",
       "4      [first, time, evei, write, bad, review, frustr...   \n",
       "...                                                  ...   \n",
       "17995  [refer, go, place, buddy, aftea, conversation,...   \n",
       "17996  [food, really, good, start, garlic, bread, cov...   \n",
       "17997  [eat, place, maybe, week, die, hard, wing, fan...   \n",
       "17998  [phoenix, airport, get, betteday, day, primari...   \n",
       "17999  [much, youngei, go, christos, first, place, es...   \n",
       "\n",
       "                                          cleaned_review  \n",
       "0      eat fioris say youll like saidnnis convenientl...  \n",
       "1      dont understand appeal ive tried place twice t...  \n",
       "2      go place foa really good beef enchilada red sa...  \n",
       "3      impressed order oyako bowl conversation go som...  \n",
       "4      first time evei write bad review frustrate her...  \n",
       "...                                                  ...  \n",
       "17995  refer go place buddy aftea conversation get sh...  \n",
       "17996  food really good start garlic bread cover toma...  \n",
       "17997  eat place maybe week die hard wing fan best ev...  \n",
       "17998  phoenix airport get betteday day primarily use...  \n",
       "17999  much youngei go christos first place escargot ...  \n",
       "\n",
       "[18000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a51100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_review, test_review, train_sentiment, test_sentiment =train_test_split(train_data.cleaned_review,train_data.sentiments,shuffle=True,random_state=0,stratify=train_data.sentiments,train_size=.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c6f11843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "number_of_train_documents = len(train_review)\n",
    "min_doc_percentage = 5/number_of_train_documents\n",
    "tf_vectorizer = TfidfVectorizer(use_idf=False)\n",
    "feature_matrix = tf_vectorizer.fit_transform(train_review)\n",
    "feature_array = feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "991c19f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.vocabulary_['able']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ef268",
   "metadata": {},
   "source": [
    "### Select K-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0ed84231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aaa', 'aaaa', 'aaaaaahnnthey', ..., 'zuma', 'zumba', 'zz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "vocab_list = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "select_k_best = SelectKBest(score_func=chi2, k= int(len(vocab_list)*.90))\n",
    "train_sentiment_np_array = np.array(train_sentiment)\n",
    "select_k_best.fit(feature_array, train_sentiment_np_array)\n",
    "mask = select_k_best.get_support()\n",
    "k_best_feature = vocab_list[mask]\n",
    "k_best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd090344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89546"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = len(tf_vectorizer.get_feature_names_out())\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbba8c2",
   "metadata": {},
   "source": [
    "### Supervised Chi-Square weight for k-best term by utilising target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "136598e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "selected_tf_vectorizer = CountVectorizer(max_features=int(len(tf_vectorizer.get_feature_names_out())*.20))\n",
    "selected_feat_array = selected_tf_vectorizer.fit_transform(train_review).toarray()\n",
    "selected_test_array = selected_tf_vectorizer.transform(test_review).toarray()\n",
    "observed_value_table = pd.DataFrame(selected_tf_vectorizer.get_feature_names_out(), columns=['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "29f77c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_frame = pd.DataFrame(selected_feat_array,columns = selected_tf_vectorizer.get_feature_names_out())\n",
    "tf_data_frame['sentiments'] = np.array(train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eda15eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_value_table['positive_sentiment'] = observed_value_table.features.apply(lambda feature: tf_data_frame.loc[tf_data_frame['sentiments']==1,feature].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c540662",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_value_table['negative_sentiment'] = observed_value_table.features.apply(lambda feature: tf_data_frame.loc[tf_data_frame['sentiments']==-1,feature].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fde3b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_value_table['total_row_count'] = observed_value_table['positive_sentiment'] + observed_value_table['negative_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e6df84d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aabc</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zoes</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoolights</th>\n",
       "      <th>zorbas</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zumba</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17280 rows × 17910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aabc  aaron  ab  aback  abandon  abc  abide  ability  ...  \\\n",
       "0       0    0     0      0   0      0        0    0      0        0  ...   \n",
       "1       0    0     0      0   0      0        0    0      0        0  ...   \n",
       "2       0    0     0      0   0      0        0    0      0        0  ...   \n",
       "3       0    0     0      0   0      0        0    0      0        0  ...   \n",
       "4       0    0     0      0   0      0        0    0      0        0  ...   \n",
       "...    ..  ...   ...    ...  ..    ...      ...  ...    ...      ...  ...   \n",
       "17275   0    0     0      0   0      0        0    0      0        0  ...   \n",
       "17276   0    0     0      0   0      0        0    0      0        0  ...   \n",
       "17277   0    0     0      0   0      0        0    0      0        0  ...   \n",
       "17278   0    0     0      0   0      0        0    0      0        0  ...   \n",
       "17279   0    0     0      0   0      0        0    0      0        0  ...   \n",
       "\n",
       "       ziti  zoes  zombie  zone  zoo  zoolights  zorbas  zucchini  zumba  \\\n",
       "0         0     0       0     0    0          0       0         0      0   \n",
       "1         0     0       0     0    0          0       0         0      0   \n",
       "2         0     0       0     0    0          0       0         0      0   \n",
       "3         0     0       0     0    0          0       0         0      0   \n",
       "4         0     0       0     0    0          0       0         0      0   \n",
       "...     ...   ...     ...   ...  ...        ...     ...       ...    ...   \n",
       "17275     0     0       0     0    0          0       0         0      0   \n",
       "17276     0     0       0     0    0          0       0         0      0   \n",
       "17277     0     0       0     0    0          0       0         0      0   \n",
       "17278     0     0       0     0    0          0       0         0      0   \n",
       "17279     0     0       0     0    0          0       0         0      0   \n",
       "\n",
       "       sentiments  \n",
       "0              -1  \n",
       "1               1  \n",
       "2              -1  \n",
       "3               1  \n",
       "4              -1  \n",
       "...           ...  \n",
       "17275           1  \n",
       "17276           1  \n",
       "17277           1  \n",
       "17278          -1  \n",
       "17279           1  \n",
       "\n",
       "[17280 rows x 17910 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8b76e366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>total_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aabc</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>zoo</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>zoolights</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>zorbas</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>zumba</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  positive_sentiment  negative_sentiment  total_row_count\n",
       "0             aa                   2                   2                4\n",
       "1            aaa                  12                   8               20\n",
       "2           aabc                   4                   0                4\n",
       "3          aaron                   5                   3                8\n",
       "4             ab                   2                   3                5\n",
       "...          ...                 ...                 ...              ...\n",
       "17904        zoo                 155                  75              230\n",
       "17905  zoolights                   3                   1                4\n",
       "17906     zorbas                   0                   6                6\n",
       "17907   zucchini                  18                  31               49\n",
       "17908      zumba                   3                   2                5\n",
       "\n",
       "[17909 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6ad609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_expected = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed929191",
   "metadata": {},
   "source": [
    "#### Calculating expected value table for chi-sqare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "81486d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_sqare_value(row_totals, positive_column_total, negative_column_total, total_sum):\n",
    "    positive_chi_value = []\n",
    "    negative_chi_value = []\n",
    "    for i in range(0, len(row_totals)):\n",
    "        positive_chi_value.append((row_totals[i]*positive_column_total)/total_sum)\n",
    "        negative_chi_value.append((row_totals[i]*negative_column_total)/total_sum)\n",
    "    return positive_chi_value, negative_chi_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ed0d168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_totals = np.array(observed_value_table['total_row_count'])\n",
    "positive_column_total = observed_value_table['positive_sentiment'].sum()\n",
    "negative_column_total = observed_value_table['negative_sentiment'].sum()\n",
    "total_sum = observed_value_table['total_row_count'].sum()\n",
    "expected_positive, expected_negative = chi_sqare_value(row_totals, positive_column_total, negative_column_total, total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "444a9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_expected['+1'] = np.array(expected_positive)\n",
    "chi_sqare_expected['-1'] = np.array(expected_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "003c0602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+1</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.708830</td>\n",
       "      <td>2.291170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.544151</td>\n",
       "      <td>11.455849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.708830</td>\n",
       "      <td>2.291170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.417660</td>\n",
       "      <td>4.582340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.136038</td>\n",
       "      <td>2.863962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>98.257734</td>\n",
       "      <td>131.742266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>1.708830</td>\n",
       "      <td>2.291170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>2.563245</td>\n",
       "      <td>3.436755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>20.933169</td>\n",
       "      <td>28.066831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>2.136038</td>\n",
       "      <td>2.863962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              +1          -1\n",
       "0       1.708830    2.291170\n",
       "1       8.544151   11.455849\n",
       "2       1.708830    2.291170\n",
       "3       3.417660    4.582340\n",
       "4       2.136038    2.863962\n",
       "...          ...         ...\n",
       "17904  98.257734  131.742266\n",
       "17905   1.708830    2.291170\n",
       "17906   2.563245    3.436755\n",
       "17907  20.933169   28.066831\n",
       "17908   2.136038    2.863962\n",
       "\n",
       "[17909 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sqare_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1d1ada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_table = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3d232fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_table['positiev_sentiments'] = ((observed_value_table['positive_sentiment'] - chi_sqare_expected['+1'])**2)/chi_sqare_expected['+1']\n",
    "chi_sqare_table['negatiev_sentiments'] = ((observed_value_table['negative_sentiment'] - chi_sqare_expected['-1'])**2)/chi_sqare_expected['-1']\n",
    "chi_sqare_table['sum'] = chi_sqare_table['positiev_sentiments'] + chi_sqare_table['negatiev_sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eb3e0fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positiev_sentiments</th>\n",
       "      <th>negatiev_sentiments</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049613</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>0.086616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.397786</td>\n",
       "      <td>1.042515</td>\n",
       "      <td>2.440301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.071961</td>\n",
       "      <td>2.291170</td>\n",
       "      <td>5.363131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.732606</td>\n",
       "      <td>0.546402</td>\n",
       "      <td>1.279008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.015126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17904</th>\n",
       "      <td>32.767748</td>\n",
       "      <td>24.439269</td>\n",
       "      <td>57.207018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905</th>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.727628</td>\n",
       "      <td>1.703219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17906</th>\n",
       "      <td>2.563245</td>\n",
       "      <td>1.911753</td>\n",
       "      <td>4.474998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>0.410998</td>\n",
       "      <td>0.306536</td>\n",
       "      <td>0.717533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>0.349446</td>\n",
       "      <td>0.260629</td>\n",
       "      <td>0.610075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17909 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       positiev_sentiments  negatiev_sentiments        sum\n",
       "0                 0.049613             0.037003   0.086616\n",
       "1                 1.397786             1.042515   2.440301\n",
       "2                 3.071961             2.291170   5.363131\n",
       "3                 0.732606             0.546402   1.279008\n",
       "4                 0.008664             0.006462   0.015126\n",
       "...                    ...                  ...        ...\n",
       "17904            32.767748            24.439269  57.207018\n",
       "17905             0.975591             0.727628   1.703219\n",
       "17906             2.563245             1.911753   4.474998\n",
       "17907             0.410998             0.306536   0.717533\n",
       "17908             0.349446             0.260629   0.610075\n",
       "\n",
       "[17909 rows x 3 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sqare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b3491",
   "metadata": {},
   "source": [
    "### Create weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b49559a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chi_sqare_weighted_features(train_feat_array, train_sentiments, p_chi_weight, n_chi_weight):\n",
    "    new_weighted_feature= []\n",
    "    sentiments = np.array(train_sentiments)\n",
    "    for i in range(0,len(sentiments)):                \n",
    "            new_weighted_feature.append(np.multiply(train_feat_array[i],p_chi_weight))\n",
    "    return new_weighted_feature        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b0f68265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_unlabled_data(features, max_chi_val):\n",
    "    weighted_data = []\n",
    "    for i in range(0,len(features)):\n",
    "        weighted_data.append(np.multiply(features[i], max_chi_val))\n",
    "    return np.array(weighted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ce01e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chi_weight = np.array(chi_sqare_table['positiev_sentiments'])\n",
    "n_chi_weight = np.array (chi_sqare_table['negatiev_sentiments'])\n",
    "weighted_selected_feat = np.array(generate_chi_sqare_weighted_features(selected_feat_array, train_sentiment,p_chi_weight,n_chi_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ce6670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiments_array = np.array(test_sentiment)\n",
    "train_sentiments_array = np.array(train_sentiment)\n",
    "chi_sqare_table['max_chi_value'] = find_max_chi_val(chi_sqare_table['positiev_sentiments'], chi_sqare_table['negatiev_sentiments'])\n",
    "weighted_test_feat = weight_unlabled_data( selected_test_array, chi_sqare_table['max_chi_value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6a6727cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.7263888888888889\n",
      "4\n",
      "0.725\n",
      "5\n",
      "0.7305555555555555\n",
      "6\n",
      "0.7319444444444444\n",
      "7\n",
      "0.7430555555555556\n",
      "8\n",
      "0.7375\n",
      "9\n",
      "0.7527777777777778\n",
      "10\n",
      "0.7513888888888889\n",
      "11\n",
      "0.7555555555555555\n",
      "12\n",
      "0.7527777777777778\n",
      "13\n",
      "0.75\n",
      "14\n",
      "0.7513888888888889\n",
      "15\n",
      "0.7472222222222222\n",
      "16\n",
      "0.7486111111111111\n",
      "17\n",
      "0.7416666666666667\n",
      "18\n",
      "0.7430555555555556\n",
      "19\n",
      "0.7402777777777778\n",
      "20\n",
      "0.7416666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "track_precision=[]\n",
    "for i in range(3,21):\n",
    "    print(i)\n",
    "    classifer = KNeighborsClassifier(n_neighbors=i,n_jobs=3,weights='distance')\n",
    "    classifer.fit(weighted_selected_feat, train_sentiments_array)\n",
    "    sentiments_predict = classifer.predict(weighted_test_feat)\n",
    "    score = metrics.accuracy_score(test_sentiments_array,sentiments_predict)\n",
    "    print(score)\n",
    "    track_precision.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd2009c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_df = pd.read_csv('1661892619_9579706_test_file.csv', names=['reviews'])\n",
    "basic_cleaning(result_test_df)\n",
    "tokenize_data(result_test_df)\n",
    "result_test_df['stop_words_cleaned'] = result_test_df.words.apply(lambda word_list: remove_stopwords(word_list))\n",
    "result_test_df['lemma_word'] = result_test_df.stop_words_cleaned.apply(lambda word_list: find_lemma_word(word_list))\n",
    "result_test_df['cleaned_review'] = result_test_df.lemma_word.apply(lambda review_list: \" \".join(review_list))\n",
    "unlabeled_test_feat_matrix = selected_tf_vectorizer.transform(result_test_df['cleaned_review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9bd8a2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 10635)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_test_feat_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e1934023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_chi_val(a,b):\n",
    "    max_chi = []\n",
    "    x = np.array(a)\n",
    "    y = np.array(b)\n",
    "    for i in range(0, len(x)):\n",
    "        max_chi.append(max(x[i],y[i]))\n",
    "    return np.array(max_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0a2345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positiev_sentiments</th>\n",
       "      <th>negatiev_sentiments</th>\n",
       "      <th>max_chi_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.416465</td>\n",
       "      <td>1.052326</td>\n",
       "      <td>1.416465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608248</td>\n",
       "      <td>0.451882</td>\n",
       "      <td>0.608248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.015199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.950556</td>\n",
       "      <td>5.163736</td>\n",
       "      <td>6.950556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.324351</td>\n",
       "      <td>0.240968</td>\n",
       "      <td>0.324351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630</th>\n",
       "      <td>2.609107</td>\n",
       "      <td>1.938369</td>\n",
       "      <td>2.609107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10631</th>\n",
       "      <td>0.787090</td>\n",
       "      <td>0.584748</td>\n",
       "      <td>0.787090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10632</th>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.011086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10633</th>\n",
       "      <td>33.096245</td>\n",
       "      <td>24.588000</td>\n",
       "      <td>33.096245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10634</th>\n",
       "      <td>0.398868</td>\n",
       "      <td>0.296329</td>\n",
       "      <td>0.398868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10635 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       positiev_sentiments  negatiev_sentiments  max_chi_value\n",
       "0                 1.416465             1.052326       1.416465\n",
       "1                 0.608248             0.451882       0.608248\n",
       "2                 0.015199             0.011292       0.015199\n",
       "3                 6.950556             5.163736       6.950556\n",
       "4                 0.324351             0.240968       0.324351\n",
       "...                    ...                  ...            ...\n",
       "10630             2.609107             1.938369       2.609107\n",
       "10631             0.787090             0.584748       0.787090\n",
       "10632             0.011086             0.008236       0.011086\n",
       "10633            33.096245            24.588000      33.096245\n",
       "10634             0.398868             0.296329       0.398868\n",
       "\n",
       "[10635 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sqare_table['max_chi_value'] = find_max_chi_val(chi_sqare_table['positiev_sentiments'], chi_sqare_table['negatiev_sentiments'])\n",
    "chi_sqare_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fbfa294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_unlabled_data(features, max_chi_val):\n",
    "    weighted_data = []\n",
    "    for i in range(0,len(features)):\n",
    "        weighted_data.append(np.multiply(features[i], max_chi_val))\n",
    "    return np.array(weighted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bd0d7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabled_weighted_data = weight_unlabled_data(unlabeled_test_feat_matrix, chi_sqare_table['max_chi_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c102cdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 10635)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabled_weighted_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e572500",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = classifer.predict(unlabled_weighted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c81080ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "outfile = open('results.csv','w')\n",
    "out = csv.writer(outfile)\n",
    "out.writerows(map(lambda x: [x], predicted_values))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebdb15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
