{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c4c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3915988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\",names=[\"sentiments\", \"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2867ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(data_frame):\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.lower())\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.translate(str.maketrans('', '', string.punctuation)))\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: review.translate(str.maketrans('', '', string.digits)))\n",
    "    data_frame['reviews'] = data_frame.reviews.apply(lambda review: re.sub(\"r[^a-z]\",'',review))\n",
    "\n",
    "    \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def tokenize_data(data_frame):\n",
    "    data_frame['words'] = data_frame.reviews.apply(lambda review: nltk.word_tokenize(review))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(list):\n",
    "    stop_words_removed = []\n",
    "    for i in list:\n",
    "        if i not in stopwords:\n",
    "            stop_words_removed.append(i)\n",
    "    return stop_words_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e811c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cleaning(train_data)\n",
    "tokenize_data(train_data)\n",
    "train_data['stop_words_cleaned'] = train_data.words.apply(lambda word_list: remove_stopwords(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbf57165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all')\n",
    "def tag_pos(list_of_words):\n",
    "    return nltk.pos_tag(list_of_words)\n",
    "\n",
    "#extraction of lemma words after taggin with pos\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "def find_lemma_word(word):\n",
    "    lemma_words=[]\n",
    "    words_with_pos = tag_pos(word)\n",
    "    for word in words_with_pos:\n",
    "        if word[1].startswith('NN'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='n'))\n",
    "        elif word[1].startswith('VB'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='v'))\n",
    "        elif word[1].startswith('JJ'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='a'))\n",
    "        elif word[1].startswith('RB'):\n",
    "            lemma_words.append(lemmatizer.lemmatize(word[0],pos='r'))\n",
    "        else:\n",
    "            lemma_words.append(word[0])\n",
    "            \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff578b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lemma_word'] = train_data.stop_words_cleaned.apply(lambda word_list: find_lemma_word(word_list))\n",
    "train_data['cleaned_review'] = train_data.lemma_word.apply(lambda review_list: \" \".join(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d192ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>reviews</th>\n",
       "      <th>words</th>\n",
       "      <th>stop_words_cleaned</th>\n",
       "      <th>lemma_word</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>eat at fioris they said  youll like it they sa...</td>\n",
       "      <td>[eat, at, fioris, they, said, youll, like, it,...</td>\n",
       "      <td>[eat, fioris, said, youll, like, saidnnis, con...</td>\n",
       "      <td>[eat, fioris, say, youll, like, saidnnis, conv...</td>\n",
       "      <td>eat fioris say youll like saidnnis convenientl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>i just dont understand the appeal  ive tried t...</td>\n",
       "      <td>[i, just, dont, understand, the, appeal, ive, ...</td>\n",
       "      <td>[dont, understand, appeal, ive, tried, place, ...</td>\n",
       "      <td>[dont, understand, appeal, ive, tried, place, ...</td>\n",
       "      <td>dont understand appeal ive tried place twice t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this is my go to place foa really good beef en...</td>\n",
       "      <td>[this, is, my, go, to, place, foa, really, goo...</td>\n",
       "      <td>[go, place, foa, really, good, beef, enchilada...</td>\n",
       "      <td>[go, place, foa, really, good, beef, enchilada...</td>\n",
       "      <td>go place foa really good beef enchilada red sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>not impressed when i ordered the oyako bowl th...</td>\n",
       "      <td>[not, impressed, when, i, ordered, the, oyako,...</td>\n",
       "      <td>[impressed, ordered, oyako, bowl, conversation...</td>\n",
       "      <td>[impressed, order, oyako, bowl, conversation, ...</td>\n",
       "      <td>impressed order oyako bowl conversation go som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>this is the first time evei wrote a bad review...</td>\n",
       "      <td>[this, is, the, first, time, evei, wrote, a, b...</td>\n",
       "      <td>[first, time, evei, wrote, bad, review, frustr...</td>\n",
       "      <td>[first, time, evei, write, bad, review, frustr...</td>\n",
       "      <td>first time evei write bad review frustrate her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>-1</td>\n",
       "      <td>i was referred to go to this place by a buddy ...</td>\n",
       "      <td>[i, was, referred, to, go, to, this, place, by...</td>\n",
       "      <td>[referred, go, place, buddy, aftea, conversati...</td>\n",
       "      <td>[refer, go, place, buddy, aftea, conversation,...</td>\n",
       "      <td>refer go place buddy aftea conversation get sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>1</td>\n",
       "      <td>the food here was really good  we started off ...</td>\n",
       "      <td>[the, food, here, was, really, good, we, start...</td>\n",
       "      <td>[food, really, good, started, garlic, bread, c...</td>\n",
       "      <td>[food, really, good, start, garlic, bread, cov...</td>\n",
       "      <td>food really good start garlic bread cover toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>1</td>\n",
       "      <td>i eat at this place maybe  a week i am die har...</td>\n",
       "      <td>[i, eat, at, this, place, maybe, a, week, i, a...</td>\n",
       "      <td>[eat, place, maybe, week, die, hard, wing, fan...</td>\n",
       "      <td>[eat, place, maybe, week, die, hard, wing, fan...</td>\n",
       "      <td>eat place maybe week die hard wing fan best ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>1</td>\n",
       "      <td>phoenix airport is getting betteday by day  i ...</td>\n",
       "      <td>[phoenix, airport, is, getting, betteday, by, ...</td>\n",
       "      <td>[phoenix, airport, getting, betteday, day, pri...</td>\n",
       "      <td>[phoenix, airport, get, betteday, day, primari...</td>\n",
       "      <td>phoenix airport get betteday day primarily use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>-1</td>\n",
       "      <td>so when i was much youngei went to christos an...</td>\n",
       "      <td>[so, when, i, was, much, youngei, went, to, ch...</td>\n",
       "      <td>[much, youngei, went, christos, first, place, ...</td>\n",
       "      <td>[much, youngei, go, christos, first, place, es...</td>\n",
       "      <td>much youngei go christos first place escargot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiments                                            reviews  \\\n",
       "0              -1  eat at fioris they said  youll like it they sa...   \n",
       "1              -1  i just dont understand the appeal  ive tried t...   \n",
       "2               1  this is my go to place foa really good beef en...   \n",
       "3              -1  not impressed when i ordered the oyako bowl th...   \n",
       "4              -1  this is the first time evei wrote a bad review...   \n",
       "...           ...                                                ...   \n",
       "17995          -1  i was referred to go to this place by a buddy ...   \n",
       "17996           1  the food here was really good  we started off ...   \n",
       "17997           1  i eat at this place maybe  a week i am die har...   \n",
       "17998           1  phoenix airport is getting betteday by day  i ...   \n",
       "17999          -1  so when i was much youngei went to christos an...   \n",
       "\n",
       "                                                   words  \\\n",
       "0      [eat, at, fioris, they, said, youll, like, it,...   \n",
       "1      [i, just, dont, understand, the, appeal, ive, ...   \n",
       "2      [this, is, my, go, to, place, foa, really, goo...   \n",
       "3      [not, impressed, when, i, ordered, the, oyako,...   \n",
       "4      [this, is, the, first, time, evei, wrote, a, b...   \n",
       "...                                                  ...   \n",
       "17995  [i, was, referred, to, go, to, this, place, by...   \n",
       "17996  [the, food, here, was, really, good, we, start...   \n",
       "17997  [i, eat, at, this, place, maybe, a, week, i, a...   \n",
       "17998  [phoenix, airport, is, getting, betteday, by, ...   \n",
       "17999  [so, when, i, was, much, youngei, went, to, ch...   \n",
       "\n",
       "                                      stop_words_cleaned  \\\n",
       "0      [eat, fioris, said, youll, like, saidnnis, con...   \n",
       "1      [dont, understand, appeal, ive, tried, place, ...   \n",
       "2      [go, place, foa, really, good, beef, enchilada...   \n",
       "3      [impressed, ordered, oyako, bowl, conversation...   \n",
       "4      [first, time, evei, wrote, bad, review, frustr...   \n",
       "...                                                  ...   \n",
       "17995  [referred, go, place, buddy, aftea, conversati...   \n",
       "17996  [food, really, good, started, garlic, bread, c...   \n",
       "17997  [eat, place, maybe, week, die, hard, wing, fan...   \n",
       "17998  [phoenix, airport, getting, betteday, day, pri...   \n",
       "17999  [much, youngei, went, christos, first, place, ...   \n",
       "\n",
       "                                              lemma_word  \\\n",
       "0      [eat, fioris, say, youll, like, saidnnis, conv...   \n",
       "1      [dont, understand, appeal, ive, tried, place, ...   \n",
       "2      [go, place, foa, really, good, beef, enchilada...   \n",
       "3      [impressed, order, oyako, bowl, conversation, ...   \n",
       "4      [first, time, evei, write, bad, review, frustr...   \n",
       "...                                                  ...   \n",
       "17995  [refer, go, place, buddy, aftea, conversation,...   \n",
       "17996  [food, really, good, start, garlic, bread, cov...   \n",
       "17997  [eat, place, maybe, week, die, hard, wing, fan...   \n",
       "17998  [phoenix, airport, get, betteday, day, primari...   \n",
       "17999  [much, youngei, go, christos, first, place, es...   \n",
       "\n",
       "                                          cleaned_review  \n",
       "0      eat fioris say youll like saidnnis convenientl...  \n",
       "1      dont understand appeal ive tried place twice t...  \n",
       "2      go place foa really good beef enchilada red sa...  \n",
       "3      impressed order oyako bowl conversation go som...  \n",
       "4      first time evei write bad review frustrate her...  \n",
       "...                                                  ...  \n",
       "17995  refer go place buddy aftea conversation get sh...  \n",
       "17996  food really good start garlic bread cover toma...  \n",
       "17997  eat place maybe week die hard wing fan best ev...  \n",
       "17998  phoenix airport get betteday day primarily use...  \n",
       "17999  much youngei go christos first place escargot ...  \n",
       "\n",
       "[18000 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d575dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_review, test_review, train_sentiment, test_sentiment =train_test_split(train_data.cleaned_review,train_data.sentiments,shuffle=True,random_state=0,stratify=train_data.sentiments,train_size=.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9781a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "number_of_train_documents = len(train_review)\n",
    "min_doc_percentage = max(5/number_of_train_documents, (len(train_review)*0.0005)/number_of_train_documents)\n",
    "tf_vectorizer = TfidfVectorizer(min_df=min_doc_percentage,use_idf=False)\n",
    "feature_matrix = tf_vectorizer.fit_transform(train_review)\n",
    "feature_array = feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fa473151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.vocabulary_['able']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a7ed1",
   "metadata": {},
   "source": [
    "### Select K-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae29ec05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'absurd', 'abysmal', ..., 'yummy', 'zero', 'zoo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "vocab_list = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "select_k_best = SelectKBest(score_func=chi2, k= int(len(vocab_list)*.20))\n",
    "train_sentiment_np_array = np.array(train_sentiment)\n",
    "select_k_best.fit(feature_array, train_sentiment_np_array)\n",
    "mask = select_k_best.get_support()\n",
    "k_best_feature = vocab_list[mask]\n",
    "k_best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c6d63",
   "metadata": {},
   "source": [
    "### Supervised Chi-Square weight for k-best term by utilising target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b1e0d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "selected_tf_vectorizer = CountVectorizer(vocabulary=k_best_feature)\n",
    "selected_feat_array = selected_tf_vectorizer.fit_transform(train_review).toarray()\n",
    "selected_test_array = selected_tf_vectorizer.transform(test_review).toarray()\n",
    "observed_value_table = pd.DataFrame(k_best_feature, columns=['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0a566329",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_frame = pd.DataFrame(selected_feat_array,columns = selected_tf_vectorizer.get_feature_names_out())\n",
    "tf_data_frame['sentiments'] = np.array(train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cbfc5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_value_table['positive_sentiment'] = observed_value_table.features.apply(lambda feature: tf_data_frame.loc[tf_data_frame['sentiments']==1,feature].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ceec8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_value_table['negative_sentiment'] = observed_value_table.features.apply(lambda feature: tf_data_frame.loc[tf_data_frame['sentiments']==-1,feature].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9f1c2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_value_table['total_row_count'] = observed_value_table['positive_sentiment'] + observed_value_table['negative_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "58bdd362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accessory</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>accomodating</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>...</th>\n",
       "      <th>youpet</th>\n",
       "      <th>yourestaurant</th>\n",
       "      <th>youtime</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoo</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17278</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17280 rows Ã— 1518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able  absurd  abysmal  accept  acceptable  accessory  accommodate  \\\n",
       "0         0       0        0       0           0          0            0   \n",
       "1         0       0        0       0           0          0            0   \n",
       "2         0       0        0       0           0          0            0   \n",
       "3         0       0        0       0           0          0            0   \n",
       "4         0       0        0       0           0          0            0   \n",
       "...     ...     ...      ...     ...         ...        ...          ...   \n",
       "17275     0       0        0       0           0          0            0   \n",
       "17276     0       0        0       0           0          0            0   \n",
       "17277     0       0        0       0           0          0            0   \n",
       "17278     0       0        0       0           0          0            0   \n",
       "17279     0       0        0       0           0          0            0   \n",
       "\n",
       "       accomodating  account  accuse  ...  youpet  yourestaurant  youtime  \\\n",
       "0                 0        0       0  ...       0              0        1   \n",
       "1                 0        0       0  ...       0              0        0   \n",
       "2                 0        0       0  ...       0              0        0   \n",
       "3                 0        0       0  ...       0              0        0   \n",
       "4                 0        0       0  ...       0              0        0   \n",
       "...             ...      ...     ...  ...     ...            ...      ...   \n",
       "17275             0        0       0  ...       0              0        0   \n",
       "17276             0        0       0  ...       0              0        0   \n",
       "17277             0        0       0  ...       0              0        0   \n",
       "17278             0        0       0  ...       0              0        0   \n",
       "17279             0        0       0  ...       0              0        0   \n",
       "\n",
       "       yuck  yucky  yum  yummy  zero  zoo  sentiments  \n",
       "0         0      0    0      0     0    0          -1  \n",
       "1         0      0    0      0     0    0           1  \n",
       "2         0      0    0      0     0    0          -1  \n",
       "3         0      0    0      0     0    0           1  \n",
       "4         0      0    0      0     0    0          -1  \n",
       "...     ...    ...  ...    ...   ...  ...         ...  \n",
       "17275     0      0    0      0     0    0           1  \n",
       "17276     0      0    0      0     0    0           1  \n",
       "17277     0      0    0      0     0    0           1  \n",
       "17278     0      0    0      0     0    0          -1  \n",
       "17279     0      0    0      0     0    0           1  \n",
       "\n",
       "[17280 rows x 1518 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "32a92196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>total_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>324</td>\n",
       "      <td>320</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absurd</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abysmal</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accept</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acceptable</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>yucky</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>yum</td>\n",
       "      <td>113</td>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>yummy</td>\n",
       "      <td>257</td>\n",
       "      <td>47</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>zero</td>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>zoo</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1517 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  positive_sentiment  negative_sentiment  total_row_count\n",
       "0           able                 324                 320              644\n",
       "1         absurd                   1                  19               20\n",
       "2        abysmal                   0                  17               17\n",
       "3         accept                  27                  88              115\n",
       "4     acceptable                  11                  57               68\n",
       "...          ...                 ...                 ...              ...\n",
       "1512       yucky                   1                   8                9\n",
       "1513         yum                 113                  15              128\n",
       "1514       yummy                 257                  47              304\n",
       "1515        zero                  16                 160              176\n",
       "1516         zoo                 155                  75              230\n",
       "\n",
       "[1517 rows x 4 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3320ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_expected = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85440e",
   "metadata": {},
   "source": [
    "#### Calculating expected value table for chi-sqare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "83674f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_sqare_value(row_totals, positive_column_total, negative_column_total, total_sum):\n",
    "    positive_chi_value = []\n",
    "    negative_chi_value = []\n",
    "    for i in range(0, len(row_totals)):\n",
    "        positive_chi_value.append((row_totals[i]*positive_column_total)/total_sum)\n",
    "        negative_chi_value.append((row_totals[i]*negative_column_total)/total_sum)\n",
    "    return positive_chi_value, negative_chi_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7dcd83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_totals = np.array(observed_value_table['total_row_count'])\n",
    "positive_column_total = observed_value_table['positive_sentiment'].sum()\n",
    "negative_column_total = observed_value_table['negative_sentiment'].sum()\n",
    "total_sum = observed_value_table['total_row_count'].sum()\n",
    "expected_positive, expected_negative = chi_sqare_value(row_totals, positive_column_total, negative_column_total, total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "79dfdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_expected['+1'] = np.array(expected_positive)\n",
    "chi_sqare_expected['-1'] = np.array(expected_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "efa88920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+1</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267.166988</td>\n",
       "      <td>376.833012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.297111</td>\n",
       "      <td>11.702889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.052545</td>\n",
       "      <td>9.947455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.708391</td>\n",
       "      <td>67.291609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.210179</td>\n",
       "      <td>39.789821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>3.733700</td>\n",
       "      <td>5.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>53.101513</td>\n",
       "      <td>74.898487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>126.116094</td>\n",
       "      <td>177.883906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>73.014580</td>\n",
       "      <td>102.985420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>95.416781</td>\n",
       "      <td>134.583219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1517 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              +1          -1\n",
       "0     267.166988  376.833012\n",
       "1       8.297111   11.702889\n",
       "2       7.052545    9.947455\n",
       "3      47.708391   67.291609\n",
       "4      28.210179   39.789821\n",
       "...          ...         ...\n",
       "1512    3.733700    5.266300\n",
       "1513   53.101513   74.898487\n",
       "1514  126.116094  177.883906\n",
       "1515   73.014580  102.985420\n",
       "1516   95.416781  134.583219\n",
       "\n",
       "[1517 rows x 2 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sqare_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e2371928",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_table = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "77bd0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqare_table['positiev_sentiments'] = ((observed_value_table['positive_sentiment'] - chi_sqare_expected['+1'])**2)/chi_sqare_expected['+1']\n",
    "chi_sqare_table['negatiev_sentiments'] = ((observed_value_table['negative_sentiment'] - chi_sqare_expected['-1'])**2)/chi_sqare_expected['-1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ad1a1a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positiev_sentiments</th>\n",
       "      <th>negatiev_sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.089784</td>\n",
       "      <td>8.571413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.417635</td>\n",
       "      <td>4.549974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.052545</td>\n",
       "      <td>5.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.988722</td>\n",
       "      <td>6.372822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.499411</td>\n",
       "      <td>7.443870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>2.001531</td>\n",
       "      <td>1.419045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>67.565471</td>\n",
       "      <td>47.902553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>135.831966</td>\n",
       "      <td>96.302118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>44.520729</td>\n",
       "      <td>31.564297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>37.206872</td>\n",
       "      <td>26.378920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1517 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      positiev_sentiments  negatiev_sentiments\n",
       "0               12.089784             8.571413\n",
       "1                6.417635             4.549974\n",
       "2                7.052545             5.000112\n",
       "3                8.988722             6.372822\n",
       "4               10.499411             7.443870\n",
       "...                   ...                  ...\n",
       "1512             2.001531             1.419045\n",
       "1513            67.565471            47.902553\n",
       "1514           135.831966            96.302118\n",
       "1515            44.520729            31.564297\n",
       "1516            37.206872            26.378920\n",
       "\n",
       "[1517 rows x 2 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sqare_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e65a9a",
   "metadata": {},
   "source": [
    "### Create weighted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bd742b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chi_sqare_weighted_features(train_feat_array, train_sentiments, p_chi_weight, n_chi_weight):\n",
    "    new_weighted_feature= []\n",
    "    sentiments = np.array(train_sentiments)\n",
    "    for i in range(0,len(sentiments)):        \n",
    "        if sentiments[i] == 1:\n",
    "            new_weighted_feature.append(np.multiply(train_feat_array[i],p_chi_weight))\n",
    "        else:\n",
    "            new_weighted_feature.append(np.multiply(train_feat_array[i],n_chi_weight))\n",
    "    return new_weighted_feature        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c435d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chi_weight = np.array(chi_sqare_table['positiev_sentiments'])\n",
    "n_chi_weight = np.array (chi_sqare_table['negatiev_sentiments'])\n",
    "weighted_selected_feat = np.array(generate_chi_sqare_weighted_features(selected_feat_array, train_sentiment,p_chi_weight,n_chi_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e9ae3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiments_array = np.array(test_sentiment)\n",
    "train_sentiments_array = np.array(train_sentiment)\n",
    "weighted_test_feat = np.array(generate_chi_sqare_weighted_features( selected_test_array, test_sentiment,p_chi_weight,n_chi_weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f5e61922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.8972222222222223\n",
      "4\n",
      "0.9027777777777778\n",
      "5\n",
      "0.8972222222222223\n",
      "6\n",
      "0.9013888888888889\n",
      "7\n",
      "0.9041666666666667\n",
      "8\n",
      "0.9055555555555556\n",
      "9\n",
      "0.9041666666666667\n",
      "10\n",
      "0.9083333333333333\n",
      "11\n",
      "0.8972222222222223\n",
      "12\n",
      "0.8972222222222223\n",
      "13\n",
      "0.9027777777777778\n",
      "14\n",
      "0.9\n",
      "15\n",
      "0.9013888888888889\n",
      "16\n",
      "0.9041666666666667\n",
      "17\n",
      "0.8972222222222223\n",
      "18\n",
      "0.8972222222222223\n",
      "19\n",
      "0.8972222222222223\n",
      "20\n",
      "0.8958333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "track_precision=[]\n",
    "for i in range(3,21):\n",
    "    print(i)\n",
    "    classifer = KNeighborsClassifier(n_neighbors=i,n_jobs=3,weights='distance')\n",
    "    classifer.fit(weighted_selected_feat, train_sentiments_array)\n",
    "    sentiments_predict = classifer.predict(weighted_test_feat)\n",
    "    score = metrics.accuracy_score(test_sentiments_array,sentiments_predict)\n",
    "    print(score)\n",
    "    track_precision.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
